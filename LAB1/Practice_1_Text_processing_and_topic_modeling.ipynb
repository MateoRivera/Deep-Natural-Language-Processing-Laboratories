{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sZIl1U-b7AzU"},"source":["#**Deep Natural Language Processing @ PoliTO**\n","\n","---\n","\n","\n","**Teaching Assistant:** Giuseppe Gallipoli\n","\n","**Credits:** Moreno La Quatra\n","\n","**Practice 1:** Text processing and topic modeling"]},{"cell_type":"markdown","metadata":{"id":"W1vQPzjM9r8c"},"source":["# **Text processing**\n","---\n","The text processing phase is a preliminary stage where the text to be manipulated is processed to be ready for subsequent analysis.\n","\n","Text processing usually entails several steps that could possibly include:\n","- **Language Identification**: identifying the language of a given text.\n","- **Tokenization**: splitting a given text in several sentences/words.\n","- **Dependency tree parsing:** analyzing the depencies between words composing the text.\n","- **Stemming/Lemmatization:** obtain the root form for each word in text.\n","- **Stopword removal**: removing words that are si commonly used that they carry very little useful information.\n","- **Part of Speech Tagging:** given a word, retrieve its part of speech (proper noun, common noun or verb).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"D2dHRmrPB22r"},"source":["### Language Identification\n","\n","| Text                                                                                                                                | Language Code |\n","|-------------------------------------------------------------------------------------------------------------------------------------|---------------|\n","| The \"Deep Natural Language Processing\" course is offered during the first semester of the second year at Politecnico di Torino      | `EN`            |\n","| Il corso \"Deep Natural Language Processing\" viene impartito al Politecnico di Torino durante il primo semestre del secondo anno.    | `IT`            |\n","| Le cours \"Deep Natural Language Processing\" est enseigné au Politecnico di Torino pendant le premier semestre de la deuxième année. | `FR`            |\n","\n","**Language Identification** is a crucial prelimiary step because each language has its own characteristics. The knowledge of the main language associated to a given text could be beneficial for all subsequent steps in text processing pipeline.\n","\n","The data collection used in this first part of the practice is provided [here](https://github.com/MorenoLaQuatra/DeepNLP/blob/main/practices/P1/langid_dataset.csv) - [source: Kaggle](https://www.kaggle.com/martinkk5575/language-detection)\n"]},{"cell_type":"markdown","metadata":{"id":"5ej_dfjm2srd"},"source":["# Exercise 1:\n","\n","Benchmark different language-detection algorithm by computing the accuracy of each approach:\n","- [fastlangid](https://pypi.org/project/fastlangid/) (built on FastText)\n","- [LangID](https://github.com/saffsd/langid.py)\n","- [langdetect](https://pypi.org/project/langdetect/)\n","\n","**Hint:** language code conversion: [iso639-lang](https://pypi.org/project/iso639-lang/)\n","\n","For each method report:\n","- Accuracy\n","- Average time per example"]},{"cell_type":"code","metadata":{"id":"dZ7xbkps3_mR"},"source":["!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/langid_dataset.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WC6GK4uLD9y9"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XIOgOZy1ENh2"},"source":["# Exercise 2\n","\n","For English-written text, apply word-level tokenization. What is the average number of words per sentence?\n","\n","Implement word-tokenization using both [nltk](https://www.nltk.org/) and [spacy](https://spacy.io/). Report the results for both of them.\n","\n","For spaCy use the `en_core_web_sm` model."]},{"cell_type":"code","metadata":{"id":"CsRSt5hmE5k7"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ySnw80QnIf2p"},"source":["# Exercise 3\n","\n","Dependency Parsing aims at analyzing the grammatical structure of sentences. The main goal is to find out related words as well as the type of the relationship between them.\n","\n","The output of this step is a dependency tree similar to the one reported in the figure below.\n","\n","![dependency tree](http://www.rangakrish.com/wp-content/uploads/2018/04/Deptree-example2.png)\n","\n","Use spacy to parse the dependency tree of a **randomly selected** sentence. You can both use English sentences or your native language (if supported in [spaCy](https://spacy.io/usage/models/)). Use [displaCy](https://explosion.ai/demos/displacy) to visualize the result in the notebook."]},{"cell_type":"code","metadata":{"id":"q474xseqTZSL"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAO1E6adVMKW"},"source":["# Exercise 4\n","For the same sentence selected in the previous step apply all the following steps:\n","1. Lemmatization: convert each word to its root form.\n","2. Stopword removal: remove language-specific stopwords.\n","3. Part of Speech Tagging: for each word in the sentence display its part-of-speech.\n","\n","For each step, print the resulting list on the console."]},{"cell_type":"code","metadata":{"id":"5z7yUuYIW-w8"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kL4KXiBkZrta"},"source":["# **Occurrence-based text representation - TF-IDF**\n","\n","---\n","\n","TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. It allows to create occurrence-based vector representation for each document.\n","\n","# Exercise 5\n","Use TF-IDF to vectorize each sentence in the original data collection. You can choose your preferred implementation for TF-IDF vectorization. It is also available on [SciKit-Learn library](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"]},{"cell_type":"code","metadata":{"id":"8rpC2R8MawAT"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_4NTwm6Qbpvx"},"source":["# Exercise 6\n","\n","Build a supervised multi-class language detector using as features the vector obtained by TF-IDF representation. Use 80% of the data to train the language detector and 20% of the data for assessing its accuracy."]},{"cell_type":"code","metadata":{"id":"HivUJsnCcUco"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5AHlGUHuaqjW"},"source":["# **Topic Modeling**\n","---\n","Occurrence-based representations are high-dimensional, what is the dimension of the generated TF-IDF vector representation?\n","Topic modeling focuses on capturing latent topics in large document corpora.\n","\n","The data collection used in this second part of the practice is provided [here](https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/CovidFake_filtered.csv) - [source: Zenodo](https://zenodo.org/record/4282522#.YVdCXcbOOpd)\n"]},{"cell_type":"markdown","metadata":{"id":"NZbbPhC6cAO8"},"source":["# Exercise 7\n","\n","Latent Semantic Indexing (LSI) models underlying concepts by using SVD (Singular Value Decomposition).\n","\n","Use [gensim](https://radimrehurek.com/gensim/) library to:\n","1. Create a corpus composed of the headlines contained in the data collection.\n","2. Generate a [dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html) to create a word -> id mapping (required by LSI module).\n","3. Using the dictionary, preprocess the corpus to obtain the representation required for LSI model training ([documentation here](https://radimrehurek.com/gensim/models/lsimodel.html)).\n","4. Inspect the top-5 topics generated by the LSI model for the analysed corpus."]},{"cell_type":"code","metadata":{"id":"PwkHsT8oft_d"},"source":["!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/CovidFake_filtered.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_HMsbJqHd_nD"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4zcmfh5UkdZm"},"source":["# Exercise 8\n","\n","The top-scored words contributing to each topic (if no stopword removal is applied) are english common words (e.g., *to, for, in, of, on*..). Moreover, missing punctuation removal could be critical for topic identification. Repeat the same procedure of Ex. 7 by adding preliminary preprocessing step to:\n","1. **remove stopwords**\n","2. **strip punctuation**\n","3. **lowercase all words**"]},{"cell_type":"code","metadata":{"id":"ZoJoiZhujDik"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zssKPqSdyYgY"},"source":["# Exercise 9\n","\n","Leveraging the same corpus used for LSI model generation, apply LDA modeling setting the number of topics to 5. Display the words most contributing to the those topics according to the LDA model."]},{"cell_type":"code","metadata":{"id":"Hp3yOxxsyX7y"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S1YVohPi7R6K"},"source":["# Exercise 10\n","\n","Using [pyLDAvis]() library build an interactive visualization for the trained LDA model."]},{"cell_type":"code","metadata":{"id":"4gEdP9uh9zPL"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 11\n","**Credits:** Giuseppe Gallipoli\n","\n","#### Introduction\n","[Large Language Models](https://en.wikipedia.org/wiki/Large_language_model) (LLMs) are a type of deep learning model capable of language generation. These models are built on deep learning architectures, primarily using neural networks, and are trained on massive amounts of text data. LLMs generally leverage the *Transformer* architecture (a groundbreaking deep architecture that you will study in more detail later in the course), which allows them to process language in context, capturing complex relationships between words and concepts.\n","\n","Large Language Models have demonstrated excellent capabilities across a wide variety of tasks, making them versatile models which can be applied in diverse scenarios and use cases.\n","\n","Given their relevance, although you have not yet covered this topic in the course, we will provide you, starting from this first laboratory practice, with practical applications showing how LLMs can be used to solve a diverse range of tasks.\\\n","Don't worry about the theoretical or more technical aspects: they will be covered in more detail in due time.\\\n","For now, the most important thing to know is that users interact with LLMs by means of a **prompt**, which is a piece of text containing the instruction or question the user wants to give or ask the model."],"metadata":{"id":"fvRXUBT8GzQD"}},{"cell_type":"markdown","source":["#### Topic Modeling using Large Language Models\n","\n","In this practice, we will use a Large Language Model to address a topic modeling-related task. Specifically, rather than modeling topic distributions as done with techniques like LSI or LDA, we will ask the LLM to extract the most relevant topic(s) from sentences (or from an entire corpus) according to different approaches.\n","\n","For this task, we will use the [Zephyr](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) 7B model, i.e., `HuggingFaceH4/zephyr-7b-beta`.\n","\n","**1<sup>st</sup> approach**: Ask the model to identify the topic(s) contained in a given sentence <u>without providing</u> a predefined list of topics to choose from.\\\n","*Example of prompt*:\\\n","Which are the most relevant topics of the following sentence?\n","\n","\\\n","<u>Suggestion</u>: To increase speed, switch to a GPU runtime. You can do this by clicking on Runtime → Change runtime type → Hardware accelerator → Select T4 GPU.\\\n","If you encounter an `OutOfMemoryError`, try restarting the session by clicking on Runtime → Restart session."],"metadata":{"id":"yhfIPfxpG0fG"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/CovidFake_filtered.csv"],"metadata":{"id":"qssSPsZdG9Qr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fill in the following code\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","import pandas as pd, random\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","df_tmodeling = ...\n","\n","PROMPT = \"Write your prompt here\"\n","\n","# It may take some time to download the model\n","model = AutoModelForCausalLM.from_pretrained('HuggingFaceH4/zephyr-7b-beta', torch_dtype=torch.float16, device_map=device)\n","tokenizer = AutoTokenizer.from_pretrained('HuggingFaceH4/zephyr-7b-beta')\n","\n","for ...\n","  full_prompt = ...\n","  input = tokenizer(full_prompt, return_tensors='pt').to(device)\n","  output = model.generate(**input, max_new_tokens=32)\n","  output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n","  ..."],"metadata":{"id":"D5d9Rd5sG-3a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2<sup>nd</sup> approach**: Ask the model to identify the topic(s) contained in a given sentence <u>providing</u> a predefined list of topics to choose from.\n","\n","*Example of prompt*:\\\n","Which are the most relevant topics of the following sentence?\\\n","Choose among: medicine, COVID, Artificial Intelligence, treatment, English literature, vaccine, gardening"],"metadata":{"id":"QJz5IGe-IKaY"}},{"cell_type":"code","source":["# fill in the following code\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","import pandas as pd, random\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","df_tmodeling = ...\n","\n","PROMPT = \"Write your prompt here\"\n","\n","# It may take some time to download the model. If you have already downloaded and loaded it, you can skip this part\n","model = AutoModelForCausalLM.from_pretrained('HuggingFaceH4/zephyr-7b-beta', torch_dtype=torch.float16, device_map=device)\n","tokenizer = AutoTokenizer.from_pretrained('HuggingFaceH4/zephyr-7b-beta')\n","\n","for ...\n","  full_prompt = ...\n","  input = tokenizer(full_prompt, return_tensors='pt').to(device)\n","  output = model.generate(**input, max_new_tokens=32)\n","  output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n","  ..."],"metadata":{"id":"2kyPbRPTIK9e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3<sup>rd</sup> approach**: Ask the model to identify the topic(s) contained in a given sentence <u>providing</u> a predefined list of topics to choose from along with the corresponding definitions.\n","\n","*Example of prompt*:\\\n","Which are the most relevant topics of the following sentence?\\\n","Choose among:\n","- medicine: treatment for illness or injury, or the study of this\n","- COVID: an infectious disease caused by a coronavirus\n","- Artificial Intelligence: computer systems that have some of the qualities that the human brain has, such as learn from data\n","- treatment: the use of drugs to cure a person of an illness or injury\n","- English literature: artistic works written in the English language, especially those with a high and lasting artistic value\n","- vaccine: a substance that is put into the body of a person or animal to protect them from a disease\n","- gardening: the job or activity of working in a garden\n","\n","Definitions are taken from the [Cambridge Dictionary](https://dictionary.cambridge.org/) and have been slightly adapted."],"metadata":{"id":"fjeUxKclIUy5"}},{"cell_type":"code","source":["# fill in the following code\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","import pandas as pd, random\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","df_tmodeling = ...\n","\n","PROMPT = \"Write your prompt here\"\n","\n","# It may take some time to download the model. If you have already downloaded and loaded it, you can skip this part\n","model = AutoModelForCausalLM.from_pretrained('HuggingFaceH4/zephyr-7b-beta', torch_dtype=torch.float16, device_map=device)\n","tokenizer = AutoTokenizer.from_pretrained('HuggingFaceH4/zephyr-7b-beta')\n","\n","for ...\n","  full_prompt = ...\n","  input = tokenizer(full_prompt, return_tensors='pt').to(device)\n","  output = model.generate(**input, max_new_tokens=32)\n","  output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n","  ..."],"metadata":{"id":"fgYzvGWVIWnc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After manually inspecting some of the outputs for each approach, here you can find some questions to reason about the results:\n","- Did you find an approach which worked best overall?\n","- Did you encounter any cases where the LLM failed?\n","- What happens if all the topics provided are irrelevant to the sentence?\n","- Does the presence of definitions improve the model's performance?\n","- What challenges or limitations did you observe?"],"metadata":{"id":"Ygjjv6SOIcp0"}}]}